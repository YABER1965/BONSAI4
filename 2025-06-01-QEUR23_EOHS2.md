---
title: QEUR23_EOHS2 - 多言語RAGのための情報を収集する
date: 2025-06-01
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_EOHS2 - 多言語RAGのための情報を収集する

## ～ やっと、Tavilyが使えるようになった ～

QEU:FOUNDER（設定年齢65歳） ： “いやあ・・・。やっとTavilyが使えるようになりました。本当に苦労しました。”

D先生（設定年齢65歳）： “ああ・・・。(Tavilyでも)やれるようになったんですか。もともと、このサービスの普及度合いから見て、使えないわけがないので、驚きは全くないですがね。・・・で？どうやっているんですか？”

![imageEHS1-3-1](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-1.jpg) 

QEU:FOUNDER ： “**LLMにTavilyに投げるための質問文を提案させた**んです。もちろん、あれほど複雑なプロンプトをTavilyのAIが解釈して、どの全部の内容を満足できる良いWeb情報を抽出できるとは思いません。ですから、プロンプトを3つのサブ質問文に分割させました。”

D先生： “そうすると、3つのプロンプトに、3つの言語、すなわち9回の検索になります。結構、検索数が多いですね。そうなると、必要な検索費用が・・・。”

![imageEHS1-3-2](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-2.jpg) 

QEU:FOUNDER  ： “Tavilyには、この手のサービスには珍しく**従量制のプランがある**でしょ？これが欲しかった・・・。じゃあ、プログラムにいきましょう。ドン！！”

```python
# ---
import os
import json
import re
import chardet
from typing import List, Dict, Any, Optional, TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import pandas as pd
import requests

# --- 定数定義 ---
JP_PROMPT = """AIの最近の技術進歩と、AIが各種の産業、仕事と生活に与える影響について調べてください。例えば：
最近のLLMの進歩に関する重要なトピック, 日本のLLM開発における固有の特徴, 米国のLLM開発における固有の特徴, 中国のLLM開発における固有の特徴, 
米国と中国のLLM開発のレベル差, シンギュラリティの定義と、その実現時期, AGIの実現時期と、現在の課題, 人工知能の金融業界への応用, 
人工知能の教育業界への応用, 人工知能の工業デザインへの応用, 人工知能の農業への応用
日本語の情報で、有効な情報量が1000語以上だけを検索してください。"""
EN_PROMPT = """Please let me know about the recent technological advances in AI and its impact on various industries, work and life. For example:
Important topics on recent LLM advances, Unique characteristics of LLM development in Japan, Unique characteristics of LLM development in the United States, 
Unique characteristics of LLM development in China, Difference in the level of LLM development between the United States and China, Definition of singularity and when it will be realized, 
When AGI will be realized and current issues, Application of AI to financial industry, Application of AI to education industry, 
Application of AI to industrial design, Application of AI to agriculture
Please only search for information in English that is valid for 1000 words or more."""
CN_PROMPT = """請探索人工智慧的最新技術進步及其對不同產業、工作和生活的影響。例如：
近期LLM發展的重要議題, 日本LLM發展的獨特之處, 美國LLM發展的獨特之處, 中國LLM發展的獨特之處, 
中美LLM發展程度的差異, 奇點(singularity)的定義及其實現時間, 通用人工智慧(AGI)何時實現以及當前問題, 人工智慧在金融業的應用, 
人工智慧在教育產業的應用, 人工智慧在工業設計上的應用, 人工智慧在農業的應用
請僅搜尋有效字元數為 1000語或以上的中文資訊。"""

# --- 文字エンコーディング処理関数 ---
def detect_and_decode(content: str) -> str:
    """文字エンコーディングを検出して正しくデコード"""
    if not content:
        return content

    try:
        # UTF-8でエンコードしてバイト列を取得（Latin-1 の代わり）
        byte_content = content.encode('utf-8')
    except Exception as e:
        print(f"UTF-8エンコードに失敗: {e}")
        return content  # エンコード失敗時は元の文字列を返す

    result = chardet.detect(byte_content)
    
    try:
        # 検出されたエンコーディングでデコード
        return byte_content.decode(result['encoding'], errors='replace')
    except:
        # デコード失敗時はUTF-8で強制デコード
        return byte_content.decode('utf-8', errors='replace')

def has_garbled_text(content: str, language: str) -> bool:
    """文字化けを検出する関数"""
    if not content:
        return False
    
    # 言語ごとに文字化けパターンを定義
    garbled_patterns = {
        "jp": r'[Ã¢â€šÂãã«ãªã´ã©ã“ã®ãµãã‘ã‚‰ã‚‹]',
        "cn": r'[Ã¥Â¿â€¦Ã¨Â§Â£Ã¤Â¸Â]',
        "en": r'[â€œâ€�â€˜â€™â€¢â€“â€”]'
    }
    
    # 共通の文字化けパターン
    common_pattern = r'[\x80-\xFF]'
    
    # 言語固有のパターン
    pattern = garbled_patterns.get(language, common_pattern)
    
    # 文字化け文字が一定割合以上あるかチェック
    garbled_chars = re.findall(pattern, content)
    if len(garbled_chars) / len(content) > 0.1:  # 10%以上が文字化け
        return True
    
    # 日本語/中国語の文字がほとんどない場合も文字化けと判定
    if language in ["jp", "cn"]:
        valid_chars = re.findall(r'[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff]', content)
        if len(valid_chars) / len(content) < 0.1:  # 10%未満しか有効文字がない
            return True
    
    return False

# --- Tavily検索ラッパー ---
def run_tavily_search(query: str, language: str, max_results: int = 3) -> List[Dict[str, Any]]:
    """Tavily APIを使用して検索を実行する関数（文字化け対策付き）"""
    TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
    if not TAVILY_API_KEY:
        raise ValueError("TAVILY_API_KEY environment variable not set")
    
    headers = {"Authorization": f"Bearer {TAVILY_API_KEY}", "Content-Type": "applica-tion/json"}
    data = {
        "query": query,
        "max_results": max_results,
        "search_depth": "advanced",
        "include_answer": False,
        "include_domains": ["wikipedia.org", "ac.jp", "edu", "gov"] if language == "jp" else []
    }
    
    try:
        response = requests.post("https://api.tavily.com/search", headers=headers, json=data)
        response.raise_for_status()
        results = response.json().get("results", [])
        
        processed = []
        for item in results:
            content = item.get("content", "")
            
            # 文字エンコーディング処理
            content = detect_and_decode(content)
            
            # 文字化けチェック
            if has_garbled_text(content, language):
                print(f"文字化けコンテンツをスキップ: {item.get('url')}")
                continue
                
            processed.append({
                "url": item.get("url"),
                "title": detect_and_decode(item.get("title", "")),
                "content": content.replace("\n\n", "\n"),
                "source": "tavily"
            })
        return processed
        
    except requests.exceptions.RequestException as e:
        print(f"Tavily API Error: {e}")
        return []

# --- LLMによる検索クエリ生成 ---
def generate_search_queries(original_prompt: str, language: str) -> List[str]:
    """LLMに最適化された検索クエリを生成する関数（JSONパース強化）"""
    llm = ChatOpenAI(
        model="deepseek-reasoner",
        temperature=0.3,
        openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
        openai_api_base="https://api.deepseek.com/v1"
    )
    
    # 言語ごとの指示を強化
    lang_instructions = {
        "jp": "JSON形式のリストで出力してください。余計なテキストは一切含めないでください。",
        "en": "Output must be a JSON-formatted list ONLY, with no additional text.",
        "cn": "請僅輸出JSON格式的列表，不要包含任何其他文字。"
    }
    
    system_prompt = f"""以下のプロンプトに基づいて、Tavily APIで検索するために最適な3つの検索文を生成してください。
各検索文は、ユーザーの目的の異なる側面をカバーするようにしてください。
    
## ユーザーの目的
{original_prompt}

## 出力指示
{lang_instructions.get(language, lang_instructions['jp'])}
出力例: ["検索クエリ1", "検索クエリ2", "検索クエリ3"]"""
    
    try:
        response = llm.invoke(system_prompt)
        content = response.content.strip()
        print(f"LLM Raw Output ({language}): {content[:200]}...")
        
        # JSON部分を抽出
        json_match = re.search(r'(\[.*?\])', content, re.DOTALL)
        if json_match:
            content = json_match.group(1)
        else:
            # JSONが見つからない場合は最初のリストを探す
            list_match = re.search(r'\[".+?"(,\s*".+?")*\]', content)
            if list_match:
                content = list_match.group(0)
        
        # JSONパース
        queries = json.loads(content)
        
        if isinstance(queries, list) and len(queries) == 3:
            return queries
        else:
            # フォールバック戦略
            print(f"LLM response parsing failed for {language}. Using fallback.")
            return [
                f"Overview of {original_prompt[:100]}",
                f"Technical details of {original_prompt[:100]}",
                f"Recent developments in {original_prompt[:100]}"
            ]
            
    except Exception as e:
        print(f"Query generation error ({language}): {e}")
        # 元のプロンプトを分割してフォールバック
        parts = re.split(r'[,、，]', original_prompt)
        return [
            parts[0] if parts else original_prompt[:100],
            parts[1] if len(parts) > 1 else "AI applications",
            parts[2] if len(parts) > 2 else "Recent AI trends"
        ]

# --- LangGraphワークフロー ---
class State(TypedDict):
    remaining_tasks: List[tuple]  # (language, prompt)のリスト
    current_task: Optional[tuple]
    search_queries: List[str]
    search_results: List[Dict]
    all_results: List[Dict]

def select_next_task(state: State) -> State:
    """次のタスクを選択するノード"""
    if state["remaining_tasks"]:
        current_task = state["remaining_tasks"].pop(0)
        return {
            "remaining_tasks": state["remaining_tasks"],
            "current_task": current_task,
            "search_queries": [],
            "search_results": []
        }
    return {"current_task": None}

def generate_queries(state: State) -> State:
    """検索クエリを生成するノード"""
    if state["current_task"] is None:
        return state
    
    lang, prompt = state["current_task"]
    queries = generate_search_queries(prompt, lang)
    return {"search_queries": queries}

def perform_searches(state: State) -> State:
    """Tavilyで検索を実行するノード（文字化け対策付き）"""
    if state["current_task"] is None or not state["search_queries"]:
        return state
    
    lang, prompt = state["current_task"]
    all_query_results = []
    
    for query in state["search_queries"]:
        raw_results = run_tavily_search(query, lang)
        
        # 結果にメタデータを追加
        for res in raw_results:
            res.update({
                "language": lang,
                "prompt_used": prompt,
                "query_used": query,
                "source": "tavily"
            })
        
        all_query_results.extend(raw_results)
    
    return {"search_results": all_query_results}

def collect_results(state: State) -> State:
    """結果を収集するノード"""
    updated_results = state.get("all_results", []) + state["search_results"]
    return {"all_results": updated_results}

def continue_or_end(state: State) -> str:
    """次のアクションを決定する条件分岐"""
    if state["remaining_tasks"]:
        return "select_next_task"
    return END

# ワークフローグラフの構築
workflow = StateGraph(State)

# ノードの追加
workflow.add_node("select_next_task", select_next_task)
workflow.add_node("generate_queries", generate_queries)
workflow.add_node("perform_searches", perform_searches)
workflow.add_node("collect_results", collect_results)

# エッジの設定
workflow.add_edge("select_next_task", "generate_queries")
workflow.add_edge("generate_queries", "perform_searches")
workflow.add_edge("perform_searches", "collect_results")

workflow.add_conditional_edges(
    "collect_results",
    continue_or_end,
    {
        "select_next_task": "select_next_task",
        END: END
    }
)

# エントリーポイントの設定
workflow.set_entry_point("select_next_task")

# ワークフローのコンパイル
app = workflow.compile()

# ---
from langgraph.graph import Graph
from IPython.display import Image, display

display(Image(app.get_graph().draw_mermaid_png()))

```

QEU:FOUNDER ： “それでは、このシステムの構造を見てみましょう。”

![imageEHS1-3-3](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-3.jpg) 

D先生： “おっ・・・。やっぱり**LangGraphを使う**んですね。”

QEU:FOUNDER ： “プログラムがこれほど複雑になったんです。うまく動かすために、モジュール化ができるLangGraphになるのは、ある程度は当然です。じゃあ、つづきに行きましょう。”

```python
# --- 実行 ---
initial_state = {
    "remaining_tasks": [("jp", JP_PROMPT), ("en", EN_PROMPT), ("cn", CN_PROMPT)],
    "current_task": None,
    "search_queries": [],
    "search_results": [],
    "all_results": []
}

# ワークフローの実行
final_state = app.invoke(initial_state)

# --- 結果処理 ---
all_results = final_state.get("all_results", [])

# DataFrameに変換
if all_results:
    df = pd.DataFrame(all_results)
    df = df[[
        "language", "prompt_used", "query_used", 
        "url", "title", "content", "source"
    ]]

    # Excelに出力 (UTF-8エンコーディングで)
    df.to_excel("tavily_search_results.xlsx", index=False, engine="openpyxl")
    print(f"検索結果をExcelファイルに保存しました: {len(df)}件のデータ")
else:
    print("検索結果が0件でした")

# コンテキストの生成（デモ用）
context = ""
for i, res in enumerate(all_results[:3]):  # 最初の3件のみ表示
    context += f"結果 {i+1}:\n"
    context += f"言語: {res.get('language', '')}\n"
    context += f"クエリ: {res.get('query_used', '')}\n"
    context += f"タイトル: {res.get('title', '')}\n"
    context += f"URL: {res.get('url', '')}\n"
    content_sample = res.get('content', '')[:200]
    context += f"内容: {content_sample}...\n\n"

print("=== 検索結果のサンプル ===")
print(context)

```

QEU:FOUNDER ： “いきなりEXCELの中身を見ましょう。”

![imageEHS1-3-4](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-4.jpg) 

D先生： “うわっ！！うまくできましたねえ・・・。”

QEU:FOUNDER ： “ちなみに、すべての言語でも、かなりうまく行っています。ここまで行くのは長かったんです。実際には、収集した情報に**「文字化け」**が多かったですから・・・。”

D先生： “そりゃそうだ・・・。じゃあ、いよいよLLMに、これらの情報を取り込ませて推論をしましょう。”

QEU:FOUNDER  ： “今回は、ここまでです。”

D先生： “ここまでなの？”

QEU:FOUNDER ： “後半に続きます。”


## ～ まとめ ～

C部長 : “時代が、徐々に変わっています。”

**(経済)**

![imageEHS1-3-5](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-5.jpg) 

**(政治)**

![imageEHS1-3-6](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-6.jpg) 

**(生活)**

![imageEHS1-3-7](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-7.jpg) 

QEU:FOUNDER ： “そうね・・・。一つ一つの細かなイシュー(issue)で、世の中が大騒ぎをしていますが、全体的に見た方が良いよね。”

![imageEHS1-3-8](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-8.jpg

C部長 : “全体的に見る・・・？”

[![MOVIE1](http://img.youtube.com/vi/fLs3Q337DAM/0.jpg)](http://www.youtube.com/watch?v=fLs3Q337DAM "内田樹さんに聞く!! 斎藤・石丸・立花3氏の共通点は「乱世のひと 長くは続かない」!?  現代社会の問題点と解決策についても語りました")

QEU:FOUNDER ： “小生は哲学をやっている人を尊敬しています。言っていることは、**いちいち重いんです**。やっぱり教養の差だねえ・・・。”

![imageEHS1-3-9](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-9.jpg) 

QEU:FOUNDER ： “このコメント（↑）を読んだとき、思わず思ったもん・・・。**「ああ・・・。平成だ・・・。」**って・・・（笑）。”

C部長 : “今回のシリーズの記号が**「EOHS」**です。どういう意味ですか？”

![imageEHS1-3-10](/2025-06-01-QEUR23_EOHS2/imageEHS1-3-10.jpg) 

QEU:FOUNDER ： “EOHSの意味は、**「END OF HEISEI」**です。もうすぐ、やっと平成が終わる。それを実感するためのシリーズです。”
