---
title: QEUR23_EOHS1 - 多言語RAGの提案
date: 2025-05-30
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_EOHS1 - 多言語RAGの提案

## ～ REASONINGモデルならではの成果です ～

D先生： “前回にやってみたことは、Tavilyのサービスを使った、非常にシンプルなRAGでした。今回は、この続きです。”

- C国のREASONINGつきAIが世界を席巻した（LOWコスト-HIGHパフォーマンス）
- LANGGRAPHでエージェントをカスタム設計できる
- Vibe Codingで複雑で高度なプログラムが、簡単に生成できる
- 本当に、Finetuningが必要かなあ・・・（疑問）

QEU:FOUNDER ： “ここからが本題です！最近のAI界隈の大きな進歩に伴い、我々・一般庶民がやれることが大いに拡大しました。今回は、REASONINGモデルのもつ能力の恩恵にあやかりたいと思います。それでは、プログラムをドン！！”

```python
# ---
import os
import re
from typing import List, Dict, Any
import pandas as pd
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SerpAPIWrapper  # SerpAPIをインポート
from langchain_core.messages import HumanMessage

# --- 定数定義(1) ---
JP_PROMPT = """AIの最近の技術進歩と、AIが各種の産業、仕事と生活に与える影響について調べてください。例えば：
最近のLLMの進歩に関する重要なトピック, 日本のLLM開発における固有の特徴, 米国のLLM開発における固有の特徴, 中国のLLM開発における固有の特徴, 
米国と中国のLLM開発のレベル差, シンギュラリティの定義と、その実現時期, AGIの実現時期と、現在の課題, 人工知能の金融業界への応用, 
人工知能の教育業界への応用, 人工知能の工業デザインへの応用, 人工知能の農業への応用"""
EN_PROMPT = """Please let me know about the recent technological advances in AI and its impact on various industries, work and life. For example:
Important topics on recent LLM advances, Unique characteristics of LLM development in Japan, Unique characteristics of LLM development in the United States, 
Unique characteristics of LLM development in China, Difference in the level of LLM development between the United States and China, Definition of singularity and when it will be realized, 
When AGI will be realized and current issues, Application of AI to financial industry, Application of AI to education industry, 
Application of AI to industrial design, Application of AI to agriculture"""
CN_PROMPT = """請探索人工智慧的最新技術進步及其對不同產業、工作和生活的影響。例如：
近期LLM發展的重要議題, 日本LLM發展的獨特之處, 美國LLM發展的獨特之處, 中國LLM發展的獨特之處, 
中美LLM發展程度的差異, 奇點(singularity)的定義及其實現時間, 通用人工智慧(AGI)何時實現以及當前問題, 人工智慧在金融業的應用, 
人工智慧在教育產業的應用, 人工智慧在工業設計上的應用, 人工智慧在農業的應用"""

# --- SerpAPI検索 ---
def run_serpapi_search(query: str, max_results: int = 3) -> List[Dict[str, Any]]:
    # SerpAPIWrapperの初期化
    search = SerpAPIWrapper(params={
        "engine": "google",
        "num": max_results,
        "api_key": os.getenv("SERPAPI_API_KEY")  # 環境変数からAPIキーを取得
    })
    
    try:
        # 検索実行
        raw_results = search.results(query)
        
        # 結果が辞書形式でない場合の処理
        if not isinstance(raw_results, dict) or 'organic_results' not in raw_results:
            print(f"SerpAPI Error: Unexpected response format")
            return []
            
        organic_results = raw_results['organic_results']
        processed = []
        
        for item in organic_results:
            # 結果アイテムの処理
            if isinstance(item, dict):
                content = item.get('snippet', '')
                # タイトルが存在しない場合は最初の100文字を使用
                title = item.get('title', content[:100] if content else 'No Title')
                
                processed.append({
                    'url': item.get('link', 'Unknown URL'),
                    'title': title,
                    'content': content
                })
            else:
                # 辞書形式でない場合はスキップ
                continue
                
        return processed
        
    except Exception as e:
        print(f"SerpAPI Exception: {e}")
        return []

# 3つの言語プロンプトで検索を実行
all_search_results = []
for lang, prompt in [('jp', JP_PROMPT), ('en', EN_PROMPT), ('cn', CN_PROMPT)]:
    print(f"Searching in {lang}: {prompt[:150]}...")  # プロンプトの一部を表示
    raw_results = run_serpapi_search(prompt)
   
    # 各結果に言語と使用されたプロンプトを追加
    for res in raw_results:
        res['language'] = lang
        res['Prompt'] = prompt
        # コンテンツの前処理
        if 'content' in res and res['content']:
            res['content'] = res['content'].replace("\n\n", "\n")
    
    all_search_results.extend(raw_results)

# 検索結果をDataFrameに変換してExcel出力
df_search = pd.DataFrame(all_search_results)
df_search.rename(columns={'url': 'URL'}, inplace=True)
df_search = df_search[['language', 'Prompt', 'URL', 'title', 'content']]
df_search.to_excel('search_results.xlsx', index=False, engine='openpyxl')

# --- LLM推論 ---
# 検索結果をLLMプロンプトに組み込む
context = ""
for res in all_search_results:
    lang = res['language']
    title = res['title']  
    url = res['url']   
    content = res['content'] 
    context += f"URL: {url}\nTitle: {title}\nContent: {content}\n\n"
print(context)

```

QEU:FOUNDER ： “ここまでの結果（↓）が出ました。何かご質問は？なにか、ムズムズしているご様子で・・・（笑）？”

![imageEHS1-2-1](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-1.jpg) 

D先生： “あともう一つ。なぜTavilyをやめたのですか？あと、EXCELファイルの中にコンテキストのないQAがあります。”

QEU:FOUNDER ： “その2つの質問には関連があります。もう、小生にもどうにもならなくて、Tavilyの適用をやめたんです。Tavilyでは、当初小生が期待したよりもうまく情報の抽出が出来なかったんです。だから、わざわざSerpAPIに変更しました。それでも、D先生が指摘したように、少量ですが「エラーみたいなもの」が出てきます。まあ、これはしょうがないと思うんです。この手のサービスは、「雑多なモノを拾ってきています」から・・・。”

D先生： “まあ、はっきり言ってサービスの質も今後は、どんどん変わってくるでしょうね。”

![imageEHS1-2-2](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-2.jpg) 

QEU:FOUNDER ： “しかし、コレって(値段が)高いですよ。**従量制の枠**を作ってくれればよかったのに・・・。まあ、いいや。次に行きましょう。”

```python
# --- 定数定義(2) ---
USER_PROMPT = """2025年以降、AI（人工知能）の進歩がさらに速くなって、人々の仕事と生活が変化しています。
AIの最近の技術進歩と、AIが各種の産業、仕事と生活に与える影響について知りたい。以下のフォーマットに示す形で
出力してください。

分析用リスト化フォーマット:
1. **最近のLLMの進歩に関する重要なトピック** - [AIの分析結果](注１)
2. **日本のLLM開発における固有の特徴** - [AIの分析結果](注１)
3. **米国のLLM開発における固有の特徴** - [AIの分析結果](注１)
4. **中国のLLM開発における固有の特徴** - [AIの分析結果](注１)
5. **米国と中国のLLM開発のレベル差** - [AIの分析結果](注１)
6. **シンギュラリティの定義と、その実現時期** - [AIの分析結果](注１)
7. **AGIの実現時期と、現在の課題** - [AIの分析結果](注１)
8. **人工知能で人々は豊かになるか** - [AIの分析結果](注１)
9. **人工知能で失業は増えるか** - [AIの分析結果](注１)
10. **人工知能の金融業界への応用** - [AIの分析結果](注１)
11. **人工知能の教育業界への応用** - [AIの分析結果](注１)
12. **人工知能の工業デザインへの応用** - [AIの分析結果](注１)
13. **人工知能の農業への応用** - [AIの分析結果](注１)
14. **人工知能の文化への影響** - [AIの分析結果](注１)
15. **人工知能の社会への影響** - [AIの分析結果](注１)

注１:[AIの分析結果]は、400文字以上600文字以内とし、リスト化しないでください。

日本語で回答してください。"""
# ---
full_prompt = f"""以下は関連する検索結果です：
{context}

この情報を基に、以下の質問に答えてください。
{USER_PROMPT}

また、以下のフォーマットに基づいて、分析に当たって、AIが最も参考にしたコンテンツ(context)のタイトル(title)のリストを生成してください。

参考にしたコンテンツ用リスト化フォーマット:
1. **最近のLLMの進歩に関する重要なトピック** -  [最も参考にしたタイトル]
2. **日本のLLM開発における固有の特徴** -  [最も参考にしたタイトル]
3. **米国のLLM開発における固有の特徴** -  [最も参考にしたタイトル]
（以下略）

"""

# LLMの初期化
llm = ChatOpenAI(
    model="qwen-max",
    temperature=0.3,
    openai_api_key=os.getenv("DASHSCOPE_API_KEY"),
    openai_api_base="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
)

# LLM呼び出し
print("LLM推論を実行中...")
response = llm.invoke([HumanMessage(content=full_prompt)])
llm_output = response.content
print("==== 推論の実行 ====")
print(llm_output)

```

QEU:FOUNDER ： “こうすると、とても面白い結果が出てきます。”

![imageEHS1-2-3](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-3.jpg) 

D先生： “普通に見えますが・・・。もっと詳細の内容を見せてください。”

==== 推論の実行 ====
### 分析用リスト化フォーマット

1. **最近のLLMの進歩に関する重要なトピック**  
   最近のLLM（大規模言語モデル）の進歩は、生成AI技術の発展に大きく寄与しています。特に、自然言語処理能力が向上し、複雑なタスクや多言語対応が可能になりました。また、NVIDIAのMegatron-LMのようなフレームワークを活用した大規模モデルの開発により、日本語など特定言語における精度が大幅に改善されています。さらに、LLMは単なるテキスト生成だけでなく、コード生成やデザイン提案など、多様な分野での応用が進んでいます。

2. **日本のLLM開発における固有の特徴**  
   日本のLLM開発は、日本語の複雑な文法構造や文化的背景に対応するため、独自の工夫が行われています。例えば、日本語特有の敬語や方言を正確に扱うために、大量の日本語データセットが使用されています。また、産業界と学術界の連携が強く、製造業や医療分野での実用的な応用が重視されています。これにより、日本市場に特化した高品質なモデルが開発されています。

3. **米国のLLM開発における固有の特徴**  

   米国では、Google DeepMindやOpenAIなどの先進企業が主導し、LLMの基礎研究から応用まで幅広く取り組んでいます。特に、大規模な計算リソースと高度なアルゴリズムを駆使して、汎用性の高いモデルを開発しています。また、倫理的課題にも積極的に取り組み、透明性や公平性を確保するためのガイドライン策定が進められています。

4. **中国のLLM開発における固有の特徴**  
   中国のLLM開発は、政府の強力な支援を受け、急速に進展しています。特に、漢字や中国語の多様性に対応するため、大規模なデータセットが活用されています。また、AIを国家戦略の一環として位置づけ、経済成長や社会問題解決に活用する方向性が明確です。ただし、プライバシーやデータ管理に関する懸念も指摘されています。

5. **米国と中国のLLM開発のレベル差**  
   米国と中国のLLM開発はそれぞれ異なる強みを持っています。米国は理論的研究と倫理的配慮が優れており、中国は実用化のスピードとスケール感が特徴です。全体的には、技術レベル自体に大きな差はなく、むしろアプローチの違いが目立ちます。ただし、長期的には倫理的枠組みや国際協力の有無が競争力を左右する可能性があります。

6. **シンギュラリティの定義と、その実現時期**  
   シンギュラリティとは、人工知能が人間の知能を超える時点を指します。この時点以降、AIが自己改善を繰り返し、予測不可能な速度で進化すると考えられています。現在のところ、具体的な実現時期は不明ですが、一部の専門家は2045年頃を予測しています。ただし、技術的・倫理的な課題が山積しており、その達成には多くの障壁が存在します。

7. **AGIの実現時期と、現在の課題**  
   AGI（汎用人工知能）は、特定のタスクに限定されず、人間並みの柔軟性を持つ知能を目指します。現在のLLMは特定領域での性能が高いものの、真の意味での汎用性にはまだ到達していません。実現時期については楽観論と慎重論が分かれており、2030年代以降が有力視されています。課題としては、知識統合や創造的思考の実現が挙げられます。

8. **人工知能で人々は豊かになるか**  

   AIは生産性向上やコスト削減を通じて経済成長を促進し、人々を豊かにする可能性があります。しかし、利益分配の不平等や雇用構造の変化が懸念されます。適切な政策や教育制度の整備が必要であり、全員が恩恵を受けられる仕組み作りが求められます。

9. **人工知能で失業は増えるか**  

   AIの普及により、一部の職種が自動化され、失業リスクが高まる可能性があります。一方で、新しい職業や役割が生まれる余地もあります。労働市場の変化に対応するためには、再教育プログラムや社会保障制度の強化が重要です。

10. **人工知能の金融業界への応用**  
 
    金融業界では、AIがリスク管理や詐欺検出、顧客サービスの自動化などで活用されています。特に、アルゴリズミックトレーディングやクレジットスコアリングの分野で顕著な成果を上げています。これにより、業務効率化と顧客満足度向上が期待されます。

11. **人工知能の教育業界への応用**  
 
    教育分野では、個別学習プランの作成や学習コンテンツの最適化にAIが利用されています。また、オンライン授業の質向上や評価システムの自動化も進んでいます。これにより、学生一人ひとりに合わせた教育提供が可能になります。

12. **人工知能の工業デザインへの応用**  
 
    工業デザインでは、AIが製品設計やプロトタイピングの効率化に貢献しています。特に、生成AIを活用したデザイン提案や材料選定の最適化が注目されています。これにより、イノベーションの加速が期待されます。

13. **人工知能の農業への応用**  
 
    農業分野では、AIが作物の生育状況監視や収穫量予測、病害虫防除などで活用されています。ドローンやセンサー技術との連携により、精密農業の実現が進んでいます。これにより、持続可能な農業の推進が可能になります。

14. **人工知能の文化への影響**  
 
    AIは芸術作品の生成や映画制作、音楽創作など、文化分野でも活用されています。これにより、新たな表現形式やクリエイティブなアイデアが生まれる一方で、著作権やオリジナル性に関する議論も活発化しています。

15. **人工知能の社会への影響**  
 
    AIは医療、交通、エネルギーなど、社会のあらゆる側面に影響を与えています。特に、スマートシティ構想や災害予測システムの導入が進んでいます。一方で、プライバシー保護やセキュリティ対策の強化が課題となっています。

---

### 参考にしたコンテンツ用リスト化フォーマット

1. **最近のLLMの進歩に関する重要なトピック** - [The rise of Large Language Models: from fundamentals to ...]
2. **日本のLLM開発における固有の特徴** - [Developing a 172B LLM with Strong Japanese Ca-pabilities ...]
3. **米国のLLM開発における固有の特徴** - [LLMs in AI Development - Key to AI's Next Break-through?]
4. **中国のLLM開発における固有の特徴** - [【新興領域/2024.08焦點】模型界的大胃王！人工智慧快速發展 ...]
5. **米国と中国のLLM開発のレベル差** - [AI と LLM が仕事の将来に与える影響]
6. **シンギュラリティの定義と、その実現時期** - [AIの進歩：AIの未来とその影響について知っておくべきこと]
7. **AGIの実現時期と、現在の課題** - [2025 AI趨勢深度研究：AGI、LLM與AI Agent]
8. **人工知能で人々は豊かになるか** - [AIの進歩：AIの未来とその影響について知っておくべきこと]
9. **人工知能で失業は増えるか** - [AI と LLM が仕事の将来に与える影響]
10. **人工知能の金融業界への応用** - [2024年度のAI最新技術動向と産業への影響]
11. **人工知能の教育業界への応用** - [AIの進歩：AIの未来とその影響について知っておくべきこと]
12. **人工知能の工業デザインへの応用** - [AI と LLM が仕事の将来に与える影響]
13. **人工知能の農業への応用** - [2024年度のAI最新技術動向と産業への影響]
14. **人工知能の文化への影響** - [AI と LLM が仕事の将来に与える影響]
15. **人工知能の社会への影響** - [AIの進歩：AIの未来とその影響について知っておくべきこと]

D先生： “なるほご。前半の分析は、まあどのLLMでもこの手の分析は得られます。しかし、後半の引用先のリストは面白いですね。AIは、**かなり均等にRAGの内容を見ている**んですね。それにしても、今回は、わざわざ**「3か国語のプロンプトを準備した」**んですよね。”

QEU:FOUNDER ： “質問です。1か国語のプロンプトを使って15件の引用を得ました。3か国語のプロンプトを使って各5件の引用を得ました。さらに、5か国語のプロンプトを使って各3件の引用を得ました。D先生は、どのケースを選びますか？”

D先生： “う～ん、正直、ケースバイケースじゃないですか？ただし、15件も取ると類似度が低くなる懸念がありますが、必要であれば取るべきかな？”

QEU:FOUNDER ： “あれ？びっくり！！1か国語のみの選択をしましたね。”

D先生： “いやいや・・・。単に、多言語にするとLLMの処理が大変だろうと・・・。”

QEU:FOUNDER ： “今回は、そこがポイントです。**REASONINGモデルを使っているので、多言語処理が楽になると思った**んです。もし、その意味がわからなければ、自分でREASONINGモデルがどのように動くのかを見てみればよいと思います。”

![imageEHS1-2-4](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-4.jpg) 

D先生： “うへぇ・・・。翻訳の場合には、REASONINGの動きはこうなるんですか？”

QEU:FOUNDER ： “このように、REASONINGが複雑に動いているため、REASONINGモデルの場合には、多国語のコンテキストを与えてもうまく動くと思ったんです。さて、プログラムも最後に行きましょう。次は回答を処理してEXCELファイルを生成します。”

```python
# ---
# 推論結果を解析してExcel出力
def generate_dataframe_from_str_output(str_output):
    # 1. 入力文字列を「分析用リスト化フォーマット」と「参考にしたコンテンツ用リスト化フォーマット」に分割
    parts = str_output.split('---', 1)
    analysis_part = parts[0]
    reference_part = parts[1]

    # 2. 「分析用リスト化フォーマット」からNO, 項目, 内容を抽出
    analysis_data = []
    entry_pattern = re.compile(r'(\d+)\. \*\*(.+?)\*\*(.*?)(?=\d+\. \*\*|\Z)', re.DOTALL)
    entries = entry_pattern.findall(analysis_part)

    for entry in entries:
        no = entry[0]
        title = entry[1]
        content_rest = entry[2].strip()

        # 「分析不要」かどうか判定
        if '（分析不要）' in content_rest:
            content = '（分析不要）'
        else:
            # URL部分を除去して本文を抽出
            content = content_rest.split('[最も参考にしたURL]:', 1)[0].strip()
            if not content:
                content = content_rest  # URLがない場合もそのまま使用

        analysis_data.append([no, title, content])

    # 3. 「参考にしたコンテンツ用リスト化フォーマット」からNO, URLを抽出
    reference_data = {}
    reference_lines = reference_part.strip().split('\n')
    for line in reference_lines:
        match = re.match(r'^(\d+)\. \*\*(.+?)\*\* - (.+)$', line, re.DOTALL)
        if match:
            no = match.group(1)
            url = match.group(3).strip()
            reference_data[no] = url

    # 4. 両方のデータをマージ
    merged_data = []
    for item in analysis_data:
        no = item[0]
        title = item[1]
        content = item[2]
        url = reference_data.get(no, '（分析不要）')  # 参考URLを取得
        merged_data.append([no, title, content, url])

    # 5. DataFrame作成
    df = pd.DataFrame(merged_data, columns=['NO', '項目', '内容', '参考としたURL'])
    return df

# 使用例（str_outputを関数に渡す）
llm_output2 = llm_output.replace("[AIの分析結果]  \n","")
df = generate_dataframe_from_str_output(llm_output2)

# 6. Excel出力
df.to_excel('output.xlsx', index=True)

```

QEU:FOUNDER ： “最終的にプロンプトへの回答は、適切に情報処理されて以下のようなEXCELになるんです。さすがに、こうすれば一気に見通しが良くなりますよね。”

![imageEHS1-2-5](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-5.jpg) 

D先生： “これはよい！”

QEU:FOUNDER ： “このディスカッションは、次の「まとめ」でやりましょう。”


## ～ まとめ ～

### ・・・ 最近は、技術的な話が増えてきたのは良いことです ・・・

QEU:FOUNDER ： “さて、今回はBONSAIプロジェクトについて語ろう。具体的には、今回のディベートをどのように進めるか・・・。その根本となる発想についてです。”

![imageEHS1-2-6](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-6.jpg) 

D先生： “当初考えたBONSAI4のスキームの概念図がこれですよね。いやあ、かなり**後から見直し**になります。さて、先日、FOUNDERはTRIZの適用も視野に入れていると・・・。さっき、TRIZについて調べていましたが、結構LLMをつかったシステムが提案されています。まあ、この手のシステムの構築はデータ準備の手間はかかりますが、構造はかなり簡単だと思います。”

![imageEHS1-2-7](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-7.jpg) 

C部長 : “我々が、いまからやってみてもメリットがあるのだろうか・・・。さらに言えば、QEUのシステムに、このTRIZの考え方が、すんなり組み込めるのか？”

![imageEHS1-2-8](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-8.jpg) 

QEU:FOUNDER ： “まあ、一旦、そのことは忘れましょう。TRIZでもBONSAIでも共通していることがあります。それは、**「情報の多様性」**です。その多様性があるからこそ、矛盾が生まれるし、同時に誤差（因子）が生まれます。”

![imageEHS1-2-9](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-9.jpg) 

QEU:FOUNDER ： “ちなみに、TRIZって、2つの（ブラスとマイナス）要素が持つ矛盾を解消するために、一般化した解決マトリックス（↑）を道具にして提案するわけです。これって、矛盾がないと始まらない。これは結局・・・？”

C部長 : “結局・・・？”

![imageEHS1-2-10](/2025-05-30-QEUR23_EOHS1/imageEHS1-2-10.jpg) 

QEU:FOUNDER ： “アウフヘーベン、完全に(言語)論理の世界でしょ？ちなみに、多様な情報を取り込み、それをアウフヘーベンさせる能力は、**REASONINGモデルの方が、そうでないモデルよりも優れていると期待しています**。”

C部長 : “最近、スゴイLLMモデルが出て来たを大騒ぎしています。それって、ユーザーの曖昧な、情報量の少ないプロンプトで豪華絢爛なアウトプットが出てくるからユーザーがそう感じるのにすぎません。モデルの中の情報量が多いだけです。”

QEU:FOUNDER ： “REASONINGモデルには、豪華絢爛LLMとはちょっと違う、**より有益な使い方がある**と思うんですよ。本当は、REASONINGのファインチューニングをしてみたい。だけど、本当にできるのか？それが問題なんですよ。”

